{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3530c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data from an external file\n",
    "#NEEDS: <FILE_STRING>, A string filename (or full filepath if not saved in same folder)\n",
    "    #Your file should include your data in CSV format (can include header row)\n",
    "    #This approach assumes your features and your outcomes are in the same file\n",
    "#RESULTS: <YOUR_DATASET>, a DataFrame variable containing your imported information\n",
    "    #See DataFrame documentation for details: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "\n",
    "from pandas import read_csv\n",
    "<YOUR_DATASET> = read_csv(<FILE_STRING>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data from a Python (SKLearn) Dataset\n",
    "#NEEDS: <DATASET_FUNCTION>, A function name for the dataset you need\n",
    "    #See the datasets in the SKLearn documentation 7.1 to 7.4: https://scikit-learn.org/stable/datasets.html\n",
    "    #This approach assumes you want your output as a Pandas DataFrame\n",
    "#RESULTS: <YOUR_DATASET>, a DataFrame variable containing your imported information\n",
    "    #See DataFrame documentation for details: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "\n",
    "import sklearn.datasets\n",
    "<YOUR_DATASET>_Bunch = sklearn.datasets.<DATASET_FUNCTION>(as_frame=True)\n",
    "<YOUR_DATASET> = <YOUR_DATASET>_Bunch.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize numeric features in a dataset\n",
    "#NEEDS: <YOUR_DATASET>, a DataFrame variable containing your feature information\n",
    "    #This approach assumes all features are numeric\n",
    "    #This approach assumes your final column (column -1) is your Outcome variable, and is ignored for Normalization\n",
    "        #This choice is most appropriate for Classification\n",
    "        #You may want to adjust this approach for regression (but remember to reverse it upon interpretation)\n",
    "#RESULTS: This functionality performs the adjustments within the DataFrame.\n",
    "    \n",
    "\n",
    "<YOUR_DATASET>.iloc[:,0:-1] = <YOUR_DATASET>.iloc[:,0:-1].apply(lambda x: (x-x.mean())/ x.std(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cda3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An alternate way to normalize features in your dataset\n",
    "    #This method is useful if you want to normalize new values to a previously set mean and Std. Dev.\n",
    "#NEEDS: A dataframe with data to normalize\n",
    "    #This approach assumes all numeric features can be normalized\n",
    "#RESULTS: This functionality performs the adjustments within the DataFrame.\n",
    "#RESULTS: myNormalizer - a new Object you can reuse to perform Normalization to the same Mean and Std. Dev.\n",
    "#RESULTS: <YOUR_DATASET>_dum_cats - a list of the one-hot dummy columns for your data, to be used for later One-Hot Encoding\n",
    "  \n",
    "import sklearn.preprocessing\n",
    "    \n",
    "<YOUR_DATASET>_num = <YOUR_DATASET>.select_dtypes(include=[numpy.number]) #Pare down your variables to only the numeric ones\n",
    "\n",
    "#Phase 1: Initialize and fit a Normalizer\n",
    "    #When complete, you can later use your Normalizer to transform other Datasets by repeating Phase 2\n",
    "myNormalizer = sklearn.preprocessing.Normalizer().fit(<YOUR_DATASET>_num.to_numpy())\n",
    "\n",
    "#Phase 2: Transform your numeric data and replace it in your original dataframe\n",
    "<YOUR_DATASET>_num[:] = myNormalizer.transform(<YOUR_DATASET>_num.to_numpy())\n",
    "<YOUR_DATASET>[<YOUR_DATASET>_num.columns] = <YOUR_DATASET>_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f431741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split your dataset into Train & Test sets, set up separate variables for Features & Outcomes\n",
    "#NEEDS: <YOUR_DATASET>, a DataFrame variable containing your feature information\n",
    "#NEEDS: <OUTCOME_NAME> a string column name (or int column number) for where your Outcome variable lives\n",
    "    #This approach assumes your Outcome variable is in the DataFrame\n",
    "#RESULTS: train_y, train_X, test_y, test_X, four DataFrames containing portions of your Dataset\n",
    "    #Those with _X contain features (i.e. everything except the Outcome variable)\n",
    "    #Those with _y contain only the Outcome variable\n",
    "    #Those with train_ are intended for training models\n",
    "    #Those with test_ are intended for testing models\n",
    "\n",
    "import sklearn.model_selection\n",
    "    \n",
    "train, test = sklearn.model_selection.train_test_split(<YOUR_DATASET>)\n",
    "\n",
    "train_y = train[<OUTCOME_NAME>]\n",
    "train_X = train.drop(<OUTCOME_NAME>,1)\n",
    "test_y = test[<OUTCOME_NAME>]\n",
    "test_X = test.drop(<OUTCOME_NAME>,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493f7118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode categorical data into an ordinal numeric variable\n",
    "#NEEDS: <YOUR_DATASET>, a DataFrame variable containing your feature information\n",
    "#NEEDS: train_X, test_X, DataFrames containing portions of your Dataset\n",
    "    #You could do your ordinal encoding before you do a train-test split if you like\n",
    "#RESULTS: train_X_ordinal, test_X_ordinal, DataFrames containing portions of your Dataset\n",
    "    #You could just save into the original variables if you don't otherwise plan to use them\n",
    "\n",
    "ordinal_encoder = sklearn.preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "ordinal_encoder.fit(<YOUR_DATASET>.drop(<OUTCOME_NAME>,1))\n",
    "train_X_ordinal = ordinal_encoder.transform(train_X)\n",
    "test_X_ordinal = ordinal_encoder.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a29eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode categorical data into a series of one-hot numeric variables (dummy variables)\n",
    "#NEEDS: <YOUR_DATASET>, a DataFrame variable containing your feature information\n",
    "#ASSUMES: All categorical variables are of type 'object' in your DataFrame\n",
    "    #This will naturally occur for strings and similar non-numeric data\n",
    "#RESULTS: <YOUR_DATASET>_dummies DataFrame with all possible category options as dummy variables\n",
    "    #You could just save into the original variable if you don't otherwise plan to use it\n",
    "\n",
    "import pandas\n",
    "<YOUR_DATASET>_dummies = pandas.get_dummies(<YOUR_DATASET>, prefix='', prefix_sep='', \n",
    "                            columns=<YOUR_DATASET>.select_dtypes(include=['object']).columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3305e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An alternate way to create one-hot dummy variables\n",
    "    #This is useful if you want to encode new values to the same one-hot dummy variables\n",
    "        #even if they contain new, never before seen values for the original variable\n",
    "#NEEDS: A dataframe to encode as One-Hot dummy variables\n",
    "#RESULTS: This functionality performs the adjustments within the DataFrame.\n",
    "#RESULTS: myOneHotEncoder - a new Object you can reuse to perform One-Hot Encoding to the same set of dummy variables\n",
    "#RESULTS: <YOUR_DATASET>_dum_cats - a list of the one-hot dummy columns for your data, to be used for later One-Hot Encoding\n",
    "    \n",
    "import sklearn.preprocessing\n",
    "    \n",
    "<YOUR_DATASET>_cat = <YOUR_DATASET>.select_dtypes(include=[numpy.object]) #Isolate categorical variables if necessary\n",
    "    \n",
    "#Phase 1: Initialize and fit a OneHotEncoder\n",
    "    #When complete, you can later use your myOneHotEncoder to transform other Datasets by repeating Phase 2\n",
    "\n",
    "<YOUR_DATASET>_cat_cols = <YOUR_DATASET>_cat.columns\n",
    "myOneHotEncoder = sklearn.preprocessing.OneHotEncoder(handle_unknown = \"ignore\", sparse = False)\n",
    "myOneHotEncoder.fit(<YOUR_DATASET>_cat.to_numpy())\n",
    "\n",
    "#Phase 2: Transform your categorical data and replace it in your original dataframe\n",
    "\n",
    "<YOUR_DATASET>_cat_dum = myOneHotEncoder.transform(<YOUR_DATASET>_cat.to_numpy())\n",
    "<YOUR_DATASET>_dum_cats = myOneHotEncoder.get_feature_names() #You can reuse this same variable for your categories later\n",
    "<YOUR_DATASET>_cat_frame = pandas.DataFrame(babyData_train_cat_dum)\n",
    "<YOUR_DATASET>[<YOUR_DATASET>_dum_cats] = <YOUR_DATASET>_cat_frame\n",
    "<YOUR_DATASET> = <YOUR_DATASET>.drop(<YOUR_DATASET>_cat_cols,1) #You must remove the old columns before training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2d147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize, fit (train), and score (test) a classifier of your choice \n",
    "#NEEDS: A particular model constructor call from SKLearn\n",
    "    # NEEDS: The constructor will be within an SKLearn module - you need to import it\n",
    "#NEEDS: train_y, train_X, test_y, test_X, four DataFrames containing portions of your Dataset\n",
    "\n",
    "<IMPORT_FOR_CLASSIFIER>\n",
    "classifier = <YOUR_SKLEARN_MODEL_CONSTRUCTOR>\n",
    "classifier.fit(train_X, train_y)\n",
    "print(classifier.score(test_X, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
