{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443afe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from pandas import read_csv\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.neighbors\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "import sklearn.svm\n",
    "\n",
    "babyData = read_csv(\"amazon_reviews_train_full.csv\")\n",
    "\n",
    "#First, explore the training dataset! See what data you can work with effectively and what you cannot\n",
    "\n",
    "#Can you convert the star rating variable into a binary \"five_stars\" outcome variable?\n",
    "\n",
    "#Can you drop any variables you don't want to work with right now?\n",
    "    #We haven't gone over how to work with text data, so headline and body may not be useful\n",
    "    #Date data is difficult to work with\n",
    "    #Other variables may be misleading\n",
    "\n",
    "#Can you normalize your numeric variables?\n",
    "\n",
    "#Can you one-hot encode your categorical variables into dummy variables?\n",
    "\n",
    "#Can you create a temporary train-test split and see how different classifiers perform on the dataset?\n",
    "\n",
    "#print(\"KNN\")\n",
    "#classifierKNN = sklearn.neighbors.KNeighborsClassifier()\n",
    "#classifierKNN.fit(train_X, train_y)\n",
    "#print(classifierKNN.score(test_X, test_y))\n",
    "\n",
    "#print(\"Naive Bayes\")\n",
    "#classifierNB = sklearn.naive_bayes.GaussianNB() #Note: \n",
    "#classifierNB.fit(train_X, train_y)\n",
    "#print(classifierNB.score(test_X, test_y))\n",
    "\n",
    "#print(\"Decision Tree\")\n",
    "#classifierDT = sklearn.tree.DecisionTreeClassifier()\n",
    "#classifierDT.fit(train_X, train_y)\n",
    "#print(classifierDT.score(test_X, test_y))\n",
    "\n",
    "#print(\"Random Forest\")\n",
    "#classifierRF = sklearn.ensemble.RandomForestClassifier()\n",
    "#classifierRF.fit(train_X, train_y)\n",
    "#print(classifierRF.score(test_X, test_y))\n",
    "\n",
    "#print(\"Logistic Regression\")\n",
    "#classifierLR = sklearn.linear_model.LogisticRegression()\n",
    "#classifierLR.fit(train_X, train_y)\n",
    "#print(classifierLR.score(test_X, test_y))\n",
    "\n",
    "#print(\"SVM\")\n",
    "#classifierSVM = sklearn.svm.SVC()\n",
    "#classifierSVM.fit(train_X, train_y)\n",
    "#print(classifierSVM.score(test_X, test_y))\n",
    "\n",
    "#Can you improve any of the classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc71b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from pandas import read_csv\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.neighbors\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "import sklearn.svm\n",
    "\n",
    "#STEP 1: Work with our Training Data\n",
    "\n",
    "babyData_train = read_csv(\"amazon_reviews_train_full.csv\")\n",
    "\n",
    "#Drop any variables you don't want to use\n",
    "\n",
    "#Convert the star_rating to our five_stars binary classification outcome variable\n",
    "\n",
    "#normalize numeric variables (note - train data and test data are not together!)\n",
    "\n",
    "#one-hot encode your categorical variables (note - train data and test data are not together!)\n",
    "\n",
    "train_y = babyData_train['five_stars']\n",
    "train_X = babyData_train.drop('five_stars',1)\n",
    "\n",
    "#STEP 2: Work with our \"Data to Predict\" (data for which we don't have the outcome variable)\n",
    "\n",
    "babyData_predict = read_csv(\"amazon_reviews_test_features.csv\")\n",
    "\n",
    "\n",
    "#Drop any variables you don't want to use\n",
    "\n",
    "#normalize numeric variables (note - train data and test data are not together!)\n",
    "\n",
    "#one-hot encode your categorical variables (note - train data and test data are not together!)\n",
    "\n",
    "#STEP 3: Create our Classifier, Make predictions, and write them to a file\n",
    "\n",
    "classifierKNN = sklearn.neighbors.KNeighborsClassifier()\n",
    "classifierKNN.fit(train_X, train_y)\n",
    "myPrediction = pandas.DataFrame(classifierKNN.predict(babyData_predict))\n",
    "myPrediction.columns = [\"five_stars\"]\n",
    "myPrediction[\"ID\"] = myPrediction.index+1\n",
    "\n",
    "myPrediction.to_csv(path_or_buf=\"amazon_reviews_guesses_YOURNAME.csv\", index = False, index_label = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d4b9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01228fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
